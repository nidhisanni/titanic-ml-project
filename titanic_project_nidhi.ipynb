{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e54a369-4224-4733-b257-39c1688a8093",
   "metadata": {},
   "source": [
    "# üö¢ Titanic Survival Prediction - Machine Learning Project\r\n",
    "\r\n",
    "**Author:** Nidhi Sanni  \r\n",
    "**Dataset:** [Kaggle Titanic: Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)\r",
    "## üìå Objective:\r\n",
    "To build a predictive model that determines whether a passenger survived the Titanic shipwreck, using machine learning algorithms and data preprocessing techniques\n",
    "\r\n",
    "## üîç Key Steps:\r\n",
    "- Data Cleaning (handling missing values)\r\n",
    "- Feature Engineering (`Title`, `FamilySize`)\r\n",
    "- Encoding categorical variables\r\n",
    "- Model Training using Random Forest Classifier\r\n",
    "- Validation & accuracy check\r\n",
    "- Creating Kaggle smission\r\n",
    "\r\n",
    "## üß† Tools & Libries:\r\n",
    "- Python üêç\r\n",
    "- Pandas, NumPy\r\n",
    "- Scikit-learn\r\n",
    "- Jyter Notebook\r\n",
    "\r\n",
    "## üéØ Accuracy:\r\n",
    "Achieved 0.8324~[youaccuracy here]**\r\n",
    "\r\n",
    "## üìÇ File:\r\n",
    "`tita_poject_nidhi.ipynb`\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "‚úÖ Next Steps:\r\n",
    "- Try other models like Logistic Regression, SVM, XGBoost\r\n",
    "- Tune hyperparameters\r\n",
    "- Plot feature importance for better insights\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ebe4eb-35f7-4860-8e97-177def5ceb87",
   "metadata": {},
   "source": [
    "STEP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8b3de2-5b2a-41f4-91fd-3c93df196430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "/n training data info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test= pd.read_csv('test.csv')\n",
    "train= pd.read_csv('train (1).csv')\n",
    "print('training data: ')\n",
    "print(train.head())\n",
    "print('/n training data info')\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eac85b-92c1-4095-9144-75a490642fdd",
   "metadata": {},
   "source": [
    "STEP 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6265cb7a-b2a8-422f-9ce3-f32dd28f9329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean missing values safely\n",
    "train['Age'].fillna(train['Age'].median(), inplace=True)\n",
    "train['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Drop Cabin column if it exists\n",
    "train.drop('Cabin', axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Check again for missing values\n",
    "print(train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbde563-f032-4376-ae35-74cc913f8091",
   "metadata": {},
   "source": [
    "Step 3: Feature Engineering (Make Data More Useful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a267159-7a3c-4024-968f-bc460363b185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Mlle          2\n",
      "Major         2\n",
      "Col           2\n",
      "Countess      1\n",
      "Capt          1\n",
      "Ms            1\n",
      "Sir           1\n",
      "Lady          1\n",
      "Mme           1\n",
      "Don           1\n",
      "Jonkheer      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract Title from Name\n",
    "train['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Check the unique titles\n",
    "print(train['Title'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "345fa1da-f96f-476f-938d-763f19b757ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n",
    "train.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb0150-e0c1-469b-81b4-515c0fdcf2b8",
   "metadata": {},
   "source": [
    "\n",
    "Step 4: Convert Categorical Data ‚Üí Numbers (Encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b997d510-4477-4878-a9e0-9882eb55578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass   Age  SibSp  Parch     Fare  FamilySize  Sex_male  \\\n",
      "0         0       3  22.0      1      0   7.2500           2      True   \n",
      "1         1       1  38.0      1      0  71.2833           2     False   \n",
      "2         1       3  26.0      0      0   7.9250           1     False   \n",
      "3         1       1  35.0      1      0  53.1000           2     False   \n",
      "4         0       3  35.0      0      0   8.0500           1      True   \n",
      "\n",
      "   Embarked_Q  Embarked_S  ...  Title_Major  Title_Master  Title_Miss  \\\n",
      "0       False        True  ...        False         False       False   \n",
      "1       False       False  ...        False         False       False   \n",
      "2       False        True  ...        False         False        True   \n",
      "3       False        True  ...        False         False       False   \n",
      "4       False        True  ...        False         False       False   \n",
      "\n",
      "   Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \n",
      "0       False      False      True      False     False      False      False  \n",
      "1       False      False     False       True     False      False      False  \n",
      "2       False      False     False      False     False      False      False  \n",
      "3       False      False     False       True     False      False      False  \n",
      "4       False      False      True      False     False      False      False  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode Sex, Embarked, Title\n",
    "train = pd.get_dummies(train, columns=['Sex', 'Embarked', 'Title'], drop_first=True)\n",
    "\n",
    "# View new columns after encoding\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a2690-96b1-4987-99e1-8d8cdab9560d",
   "metadata": {},
   "source": [
    "\n",
    "Step 5: Train a Machine Learning Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d953a4f5-1874-4c18-8a5d-4678092774ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target (y) and features (X)\n",
    "X = train.drop('Survived', axis=1)\n",
    "y = train['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48974a11-be6d-4b3b-8f93-b006ede9e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80% training, 20% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b8c8fc4-18a3-4829-a649-e57aa66045c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Check accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ad13f-7d42-45d9-8bb4-0b9ae9abea26",
   "metadata": {},
   "source": [
    "\n",
    "Step 6: Predict on the Test Data and Create Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46e87e53-5dad-4231-b550-14e3f2cfe49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload test data\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Fill missing Age and Fare\n",
    "test['Age'].fillna(train['Age'].median(), inplace=True)\n",
    "test['Fare'].fillna(train['Fare'].median(), inplace=True)\n",
    "\n",
    "# Extract Title\n",
    "test['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Create FamilySize\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n",
    "\n",
    "# Drop unwanted columns\n",
    "test.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# One-hot encoding\n",
    "test = pd.get_dummies(test, columns=['Sex', 'Embarked', 'Title'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03405b20-5b8f-4478-88d2-f5d185b35f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing columns to test set (with 0 values)\n",
    "for col in X.columns:\n",
    "    if col not in test.columns:\n",
    "        test[col] = 0\n",
    "\n",
    "# Reorder columns to match training set\n",
    "test = test[X.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e516cd3c-f118-4f1b-891f-b5dc3f973971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "test_preds = model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fdb9b16-6a4a-4391-9803-90357c7f110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created \n"
     ]
    }
   ],
   "source": [
    "# Load PassengerId again (since we dropped it earlier)\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': test_preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('titanic_submission.csv', index=False)\n",
    "print(\"Submission file created \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
